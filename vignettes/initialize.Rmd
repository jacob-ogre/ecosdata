---
title: "Initialize ECOS archive"
author: "Jacob Malcom, Defenders of Wildlife"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    theme: yeti
---

```{r setup, include=FALSE}
library(dplyr)
library(ecosdata)
library(ecosscraper)
library(knitr)
library(parallel)

NCORE <- detectCores() - 1
```

# Get Base dfs

## TECP_table

Before initializing the run across all T & E species, we need to get up-to-date
data from the main table of ECOS:

```{r TECP}
TECP_init <- get_TECP_baseline()
TECP_table <- TECP_init$TECP_table
TECP_summary <- TECP_init$TECP_summary
kable(head(TECP_table))
```

At this initial scrape, it is interesting to see one Hawaiian species' common
name, which features backticks, gets turned to "code" (_Abutilon menziesii_). 
We will keep the summary df of the TECP_table for joining with the per-species 
page scrape summary data, to be saved later.

## Filter species

By default, `get_TECP_table` records foreign + domestic and T & E + candidates /
proposed. But we're primarily interested in domestic T & E only, so we filter:

```{r domestic}
dom <- filter_listed(TECP_table) %>% filter_domestic()
dom_MD5 <- digest(dom)
kable(head(dom))
```

# Species' Pages

## Downloading

Now we can get every species' ECOS page and save them all locally, which will
facilitate all sorts of processing:

```{r scrape_species_pages}
files <- mclapply(dom$Species_Page, 
                  FUN = GET_page,
                  pause = TRUE,
                  mc.cores = NCORE)

# Using a loop because it's plenty fast:
fnames <- rep("", length(files))
for(i in 1:length(files)) {
  fname <- paste0("/datadrive/data/ECOS/html/", 
                  dom$Species_Code[i], "_", Sys.Date(), ".html")
  if(!is.na(files[[i]])) {
    writeLines(files[[i]], con = fname)
    fnames[i] <- fname 
  } else {
    warning(paste("Problem with URL:", dom$Species_Page[i]))
    fnames[i] <- NA
  }
}

ECOS_dl_data <- data_frame(Page = dom$Species_Page,
                           File = fnames,
                           Date_DL = Sys.Date())
```

Oh, the possibilities!

## Processing

Now that we have local copies, it's time to get out all of the information.

First, we need a simple table of pages + the MD5 hash of the page content:

```{r md5_hash}
md5s <- mclapply(ECOS_dl_data$File, 
                 species_page_md5,
                 mc.cores = NCORE)
ECOS_dl_data$MD5 <- unlist(md5s)
```

# Save .rdas

Last, for now, we will combine the data and save it as `.rda`:

```{r save_data}
TECP_domestic <- dom
save(ECOS_dl_data, con = "/datadrive/data/ECOS/rda/ECOS_dl_data.rda")
save(TECP_domestic, con = "/datadrive/data/ECOS/rda/TECP_domestic.rda")
save(TECP_summary, con = "/datadrive/data/ECOS/rda/TECP_summary.rda")
kable(head(ECOS_dl_data))
# TECP_summary$Type <- "TECP_table"
# sp_summary$Type <- rep("species_page", length(sp_summary$Species))
# ECOS_summary <- rbind(TECP_summary, sp_summary)
# kable(head(ECOS_summary))
# save(ECOS_summary, file = "../data/ECOS_summary.rda")
```
